{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Derrandra/samsung-object-detection/blob/main/Train_YOLO_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "z8O6z-wVcPEF"
      },
      "outputs": [],
      "source": [
        "# Unzip images to a custom data folder\n",
        "!unzip -q /content/data.zip -d /content/custom_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Automated data split:"
      ],
      "metadata": {
        "id": "f2ohNAhWj41n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O /content/train_val_split.py https://raw.githubusercontent.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/refs/heads/main/utils/train_val_split.py\n",
        "\n",
        "# TO DO: Improve robustness of train_val_split.py script so it can handle nested data folders, etc\n",
        "!python train_val_split.py --datapath=\"/content/custom_data\" --train_pct=0.9"
      ],
      "metadata": {
        "id": "8X62eFTugosf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85b99211-996c-4c58-993b-2982fd7f177e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-04 14:32:28--  https://raw.githubusercontent.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/refs/heads/main/utils/train_val_split.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3203 (3.1K) [text/plain]\n",
            "Saving to: ‘/content/train_val_split.py’\n",
            "\n",
            "/content/train_val_ 100%[===================>]   3.13K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-09-04 14:32:29 (52.8 MB/s) - ‘/content/train_val_split.py’ saved [3203/3203]\n",
            "\n",
            "Created folder at /content/data/train/images.\n",
            "Created folder at /content/data/train/labels.\n",
            "Created folder at /content/data/validation/images.\n",
            "Created folder at /content/data/validation/labels.\n",
            "Number of image files: 1244\n",
            "Number of annotation files: 1244\n",
            "Images moving to train: 1119\n",
            "Images moving to validation: 125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "EMEDk5byzxY5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dd2118a-f58b-46c3-bf68-b2747f88d6b5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.193-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.193-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.193 ultralytics-thop-2.0.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Python function to automatically create data.yaml config file\n",
        "# 1. Reads \"classes.txt\" file to get list of class names\n",
        "# 2. Creates data dictionary with correct paths to folders, number of classes, and names of classes\n",
        "# 3. Writes data in YAML format to data.yaml\n",
        "\n",
        "import yaml\n",
        "import os\n",
        "\n",
        "def create_data_yaml(path_to_classes_txt, path_to_data_yaml):\n",
        "\n",
        "  # Read class.txt to get class names\n",
        "  if not os.path.exists(path_to_classes_txt):\n",
        "    print(f'classes.txt file not found! Please create a classes.txt labelmap and move it to {path_to_classes_txt}')\n",
        "    return\n",
        "  with open(path_to_classes_txt, 'r') as f:\n",
        "    classes = []\n",
        "    for line in f.readlines():\n",
        "      if len(line.strip()) == 0: continue\n",
        "      classes.append(line.strip())\n",
        "  number_of_classes = len(classes)\n",
        "\n",
        "  # Create data dictionary\n",
        "  data = {\n",
        "      'path': '/content/data',\n",
        "      'train': 'train/images',\n",
        "      'val': 'validation/images',\n",
        "      'nc': number_of_classes,\n",
        "      'names': classes\n",
        "  }\n",
        "\n",
        "  # Write data to YAML file\n",
        "  with open(path_to_data_yaml, 'w') as f:\n",
        "    yaml.dump(data, f, sort_keys=False)\n",
        "  print(f'Created config file at {path_to_data_yaml}')\n",
        "\n",
        "  return\n",
        "\n",
        "# Define path to classes.txt and run function\n",
        "path_to_classes_txt = '/content/custom_data/classes.txt'\n",
        "path_to_data_yaml = '/content/data.yaml'\n",
        "\n",
        "create_data_yaml(path_to_classes_txt, path_to_data_yaml)\n",
        "\n",
        "print('\\nFile contents:\\n')\n",
        "!cat /content/data.yaml"
      ],
      "metadata": {
        "id": "4letvP7X12ji",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9a6cd31-0c07-4c8b-bd9b-237d7f310711"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created config file at /content/data.yaml\n",
            "\n",
            "File contents:\n",
            "\n",
            "path: /content/data\n",
            "train: train/images\n",
            "val: validation/images\n",
            "nc: 8\n",
            "names:\n",
            "- '0'\n",
            "- car\n",
            "- kraba\n",
            "- mortorbike\n",
            "- suv\n",
            "- truck\n",
            "- tuktuk\n",
            "- van\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8bbpob1gTPlo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a1d1bf5-9d6b-44f1-a62e-72c794f79dc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PRO TIP 💡 Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
            "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
            "\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov5su.pt to 'yolov5su.pt': 100% ━━━━━━━━━━━━ 17.7MB 42.6MB/s 0.4s\n",
            "Ultralytics 8.3.193 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=60, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 18.2MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=8\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n",
            " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
            " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
            " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
            " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n",
            " 24        [17, 20, 23]  1   2119144  ultralytics.nn.modules.head.Detect           [8, [128, 256, 512]]          \n",
            "YOLOv5s summary: 153 layers, 9,125,288 parameters, 9,125,272 gradients, 24.1 GFLOPs\n",
            "\n",
            "Transferred 421/427 items from pretrained weights\n",
            "Freezing layer 'model.24.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4MB 83.3MB/s 0.1s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1697.3±683.8 MB/s, size: 72.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data/train/labels... 1119 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1119/1119 2.1Kit/s 0.5s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/train/labels.cache\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 62, len(boxes) = 8940. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 384.4±195.3 MB/s, size: 44.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/validation/labels... 125 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 125/125 968.7it/s 0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/data/validation/labels.cache\n",
            "WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 18, len(boxes) = 802. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
            "Plotting labels to /content/runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/train\u001b[0m\n",
            "Starting training for 60 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/60       5.7G      1.663      1.729      1.327        318        640: 100% ━━━━━━━━━━━━ 70/70 2.4it/s 28.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.1it/s 3.7s\n",
            "                   all        125        802      0.534      0.429      0.411      0.235\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/60      6.23G      1.684      1.316      1.307        146        640: 100% ━━━━━━━━━━━━ 70/70 2.9it/s 23.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.7it/s 2.4s\n",
            "                   all        125        802       0.66      0.136      0.154     0.0782\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/60      6.26G      1.684      1.317      1.334        440        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 25.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.3it/s 1.8s\n",
            "                   all        125        802      0.689      0.419      0.393      0.178\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/60      6.97G      1.691      1.288      1.343        159        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 25.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.7it/s 1.5s\n",
            "                   all        125        802      0.554      0.685      0.411      0.244\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/60         7G      1.721      1.305      1.365        141        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 24.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.8it/s 1.4s\n",
            "                   all        125        802      0.832      0.405      0.405      0.177\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/60      7.03G      1.666      1.235      1.324        148        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 24.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.4it/s 1.7s\n",
            "                   all        125        802      0.926      0.308      0.414      0.238\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/60      7.06G      1.617      1.201      1.299        140        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 25.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.9it/s 1.4s\n",
            "                   all        125        802      0.903      0.384      0.407      0.134\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/60      7.09G       1.61      1.202      1.306        121        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 24.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.7it/s 1.5s\n",
            "                   all        125        802      0.746      0.348      0.303       0.15\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/60      7.12G      1.596      1.156      1.285        252        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 24.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.8it/s 1.4s\n",
            "                   all        125        802      0.809       0.41      0.526      0.279\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/60      7.16G       1.56      1.127       1.27        165        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 25.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.6it/s 1.5s\n",
            "                   all        125        802      0.734      0.417      0.426      0.183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/60      7.19G      1.577      1.128      1.274        220        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 24.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.9it/s 1.4s\n",
            "                   all        125        802       0.87      0.324      0.663      0.367\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/60      7.22G      1.536      1.104      1.271        326        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 25.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.5it/s 1.6s\n",
            "                   all        125        802      0.562      0.688       0.66      0.435\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/60      7.25G      1.528      1.069       1.25        123        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 25.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.7it/s 1.5s\n",
            "                   all        125        802      0.594      0.681      0.657      0.436\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/60      7.28G      1.514      1.068      1.248        100        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 24.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.8it/s 1.4s\n",
            "                   all        125        802      0.516      0.693      0.658      0.336\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/60      7.31G      1.488      1.062      1.239        436        640: 100% ━━━━━━━━━━━━ 70/70 2.7it/s 25.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.7it/s 1.5s\n",
            "                   all        125        802      0.762      0.359      0.659      0.315\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/60      7.34G      1.457      1.033      1.225        173        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 24.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.7it/s 1.5s\n",
            "                   all        125        802      0.681      0.614      0.678      0.424\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/60      7.38G      1.509       1.03      1.222        383        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 25.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.5it/s 1.1s\n",
            "                   all        125        802      0.808      0.654      0.665      0.359\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/60      4.46G      1.429     0.9828      1.202        128        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 24.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.4it/s 1.6s\n",
            "                   all        125        802      0.926      0.383      0.446       0.28\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/60       4.9G      1.437      1.006      1.201        126        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 24.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.7it/s 1.5s\n",
            "                   all        125        802      0.872      0.374      0.663       0.39\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/60       4.9G      1.446     0.9865      1.199        106        640: 100% ━━━━━━━━━━━━ 70/70 2.9it/s 24.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.4it/s 1.6s\n",
            "                   all        125        802      0.879      0.377      0.497      0.359\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/60       4.9G      1.386     0.9418      1.185        122        640: 100% ━━━━━━━━━━━━ 70/70 2.9it/s 24.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.7it/s 2.3s\n",
            "                   all        125        802      0.557      0.694      0.671       0.42\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/60       4.9G      1.408      0.967      1.178        274        640: 100% ━━━━━━━━━━━━ 70/70 3.0it/s 23.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.8it/s 2.2s\n",
            "                   all        125        802      0.868      0.328      0.545      0.332\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/60      4.93G      1.427     0.9495      1.175        129        640: 100% ━━━━━━━━━━━━ 70/70 2.9it/s 24.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.7it/s 2.3s\n",
            "                   all        125        802      0.888      0.325      0.671      0.369\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/60      4.96G      1.375     0.9326      1.167        119        640: 100% ━━━━━━━━━━━━ 70/70 2.9it/s 24.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.8it/s 2.2s\n",
            "                   all        125        802      0.737      0.681      0.672      0.397\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/60      4.99G      1.397     0.9221       1.16        187        640: 100% ━━━━━━━━━━━━ 70/70 2.9it/s 24.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.9it/s 2.1s\n",
            "                   all        125        802      0.825      0.648      0.671       0.47\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/60      5.03G      1.357     0.9047      1.154        136        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 24.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.7it/s 1.5s\n",
            "                   all        125        802      0.714       0.66      0.674      0.449\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/60      5.06G      1.349     0.8908      1.148        137        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 25.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.9it/s 1.4s\n",
            "                   all        125        802      0.868      0.592      0.669      0.422\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/60      5.79G      1.339     0.8813       1.13        285        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 25.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.6it/s 1.5s\n",
            "                   all        125        802      0.754       0.64       0.67      0.423\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/60      5.82G      1.341     0.8871      1.137        157        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 25.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.6it/s 1.5s\n",
            "                   all        125        802      0.747      0.668      0.677      0.525\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/60      5.85G      1.276     0.8405      1.124        124        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 25.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.8it/s 1.4s\n",
            "                   all        125        802      0.793      0.643      0.675      0.475\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      31/60      5.88G      1.261     0.8535      1.125        220        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 25.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.6it/s 1.6s\n",
            "                   all        125        802      0.747       0.67      0.676      0.482\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      32/60      5.91G      1.269      0.834       1.11        148        640: 100% ━━━━━━━━━━━━ 70/70 2.7it/s 26.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.7it/s 1.5s\n",
            "                   all        125        802       0.52      0.672      0.553      0.417\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      33/60      5.95G      1.267     0.8353      1.117        193        640: 100% ━━━━━━━━━━━━ 70/70 2.7it/s 25.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.7it/s 1.5s\n",
            "                   all        125        802      0.323      0.704      0.681        0.5\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      34/60      5.98G      1.274     0.8329      1.118        267        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 24.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.7it/s 1.5s\n",
            "                   all        125        802      0.884       0.64      0.675      0.499\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      35/60      6.01G      1.229     0.8161      1.113        225        640: 100% ━━━━━━━━━━━━ 70/70 2.9it/s 24.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.4it/s 1.7s\n",
            "                   all        125        802      0.864      0.642      0.675      0.424\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      36/60      6.04G      1.256      0.805      1.104        422        640: 100% ━━━━━━━━━━━━ 70/70 2.9it/s 23.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.0it/s 2.0s\n",
            "                   all        125        802      0.769      0.376      0.447      0.365\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      37/60      6.07G       1.23     0.8021      1.106        415        640: 100% ━━━━━━━━━━━━ 70/70 2.9it/s 24.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.6it/s 2.4s\n",
            "                   all        125        802      0.763      0.665      0.676      0.452\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      38/60       6.1G      1.225     0.7761      1.092        113        640: 100% ━━━━━━━━━━━━ 70/70 2.9it/s 24.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.8it/s 2.3s\n",
            "                   all        125        802      0.916      0.611       0.68      0.454\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      39/60      6.13G      1.216     0.7798      1.092        194        640: 100% ━━━━━━━━━━━━ 70/70 2.9it/s 23.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.0it/s 2.0s\n",
            "                   all        125        802      0.916      0.618      0.679      0.505\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      40/60      6.17G      1.181     0.7563      1.083        370        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 25.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.1it/s 1.9s\n",
            "                   all        125        802      0.753      0.679      0.676      0.528\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      41/60       6.2G      1.214     0.7716      1.077        326        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 24.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.4it/s 1.7s\n",
            "                   all        125        802      0.833      0.655      0.679      0.504\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      42/60      6.23G      1.188      0.755      1.077        178        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 24.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.5it/s 1.6s\n",
            "                   all        125        802      0.892       0.61       0.68      0.505\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      43/60      6.26G      1.166     0.7435      1.072        271        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 24.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.2it/s 1.2s\n",
            "                   all        125        802      0.631      0.698      0.679      0.482\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      44/60      6.29G      1.152     0.7304      1.067        338        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 25.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.8it/s 1.4s\n",
            "                   all        125        802      0.874      0.623      0.679       0.48\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      45/60      6.32G      1.145     0.7118      1.052        177        640: 100% ━━━━━━━━━━━━ 70/70 2.7it/s 25.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.6it/s 1.6s\n",
            "                   all        125        802      0.728      0.674      0.679      0.482\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      46/60      6.35G      1.155      0.727       1.06        118        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 24.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.8it/s 1.4s\n",
            "                   all        125        802      0.877      0.616      0.677      0.505\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      47/60      6.39G      1.157     0.7195      1.063        159        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 25.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.5it/s 1.6s\n",
            "                   all        125        802      0.867      0.624      0.677      0.503\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      48/60      6.42G      1.154     0.7115      1.047        576        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 24.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.9it/s 1.4s\n",
            "                   all        125        802      0.873      0.611      0.677      0.504\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      49/60      6.45G      1.114     0.6909      1.043        177        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 25.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.1it/s 1.3s\n",
            "                   all        125        802      0.871      0.625      0.679      0.531\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      50/60      6.48G      1.084     0.6859      1.042        153        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 24.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.0it/s 1.3s\n",
            "                   all        125        802      0.877       0.62      0.683      0.483\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      51/60      6.51G      1.082      0.655      1.033         80        640: 100% ━━━━━━━━━━━━ 70/70 2.6it/s 26.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.4it/s 1.7s\n",
            "                   all        125        802      0.893      0.611      0.681      0.456\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      52/60      6.54G      1.065     0.6258       1.02        264        640: 100% ━━━━━━━━━━━━ 70/70 3.0it/s 23.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.1it/s 1.3s\n",
            "                   all        125        802      0.879      0.606      0.677      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      53/60      6.57G      1.046     0.6174      1.018         47        640: 100% ━━━━━━━━━━━━ 70/70 2.8it/s 24.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.8it/s 1.4s\n",
            "                   all        125        802      0.891      0.622      0.682      0.534\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      54/60      6.61G      1.014     0.6008      1.002         41        640: 100% ━━━━━━━━━━━━ 70/70 2.9it/s 24.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.2it/s 1.2s\n",
            "                   all        125        802      0.882      0.614      0.682      0.458\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      55/60      6.64G      1.004     0.5923     0.9923         35        640: 100% ━━━━━━━━━━━━ 70/70 2.9it/s 24.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.6it/s 1.5s\n",
            "                   all        125        802      0.889      0.617      0.682      0.486\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      56/60      6.67G     0.9986     0.5883     0.9904         85        640: 100% ━━━━━━━━━━━━ 70/70 2.9it/s 23.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 3.0it/s 1.3s\n",
            "                   all        125        802      0.902      0.621      0.682      0.509\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      57/60       6.7G     0.9929     0.5805      0.983         78        640: 100% ━━━━━━━━━━━━ 70/70 2.9it/s 24.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.9it/s 1.4s\n",
            "                   all        125        802      0.885      0.622      0.682      0.535\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      58/60      6.73G     0.9665     0.5687     0.9866         41        640: 100% ━━━━━━━━━━━━ 70/70 2.9it/s 24.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.7it/s 1.5s\n",
            "                   all        125        802      0.855      0.618      0.684       0.51\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      59/60      6.76G      0.986     0.5742     0.9874         79        640: 100% ━━━━━━━━━━━━ 70/70 2.9it/s 24.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.7it/s 1.5s\n",
            "                   all        125        802      0.886      0.615      0.684      0.536\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      60/60      6.79G     0.9634     0.5576      0.981         79        640: 100% ━━━━━━━━━━━━ 70/70 2.9it/s 24.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 2.9it/s 1.4s\n",
            "                   all        125        802      0.886      0.612      0.684      0.537\n",
            "\n",
            "60 epochs completed in 0.452 hours.\n",
            "Optimizer stripped from /content/runs/detect/train/weights/last.pt, 18.5MB\n",
            "Optimizer stripped from /content/runs/detect/train/weights/best.pt, 18.5MB\n",
            "\n",
            "Validating /content/runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.3.193 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLOv5s summary (fused): 84 layers, 9,114,632 parameters, 0 gradients, 23.8 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 4/4 1.2it/s 3.4s\n",
            "                   all        125        802      0.886      0.612      0.684      0.537\n",
            "                     0        122        799      0.901      0.446      0.746      0.455\n",
            "                   car          1          1        0.7          1      0.995      0.895\n",
            "                   suv          1          1      0.942          1      0.995      0.796\n",
            "                 truck          1          1          1          0          0          0\n",
            "Speed: 0.2ms preprocess, 4.9ms inference, 0.0ms loss, 6.6ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/train\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ],
      "source": [
        "!yolo train data=/content/data.yaml model=yolov5s.pt epochs=60 imgsz=640"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training algorithm will parse the images in the training and validation directories and then start training the model. At the end of each training epoch, the program runs the model on the validation dataset and reports the resulting mAP, precision, and recall. As training continues, the mAP should generally increase with each epoch. Training will end once it goes through the number of epochs specified by `epochs`.\n",
        "\n",
        "> **NOTE:** Make sure to allow training to run to completion, because an optimizer runs at the end of training that strips out unneeded layers from the model.\n",
        "\n",
        "The best trained model weights will be saved in `content/runs/detect/train/weights/best.pt`. Additional information about training is saved in the `content/runs/detect/train` folder, including a `results.png` file that shows how loss, precision, recall, and mAP progressed over each epoch."
      ],
      "metadata": {
        "id": "vv0EYWJ5V6mC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo8BJRXeg0Ap"
      },
      "source": [
        "#6.&nbsp;Test Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model has been trained; now it's time to test it! The commands below run the model on the images in the validation folder and then display the results for the first 10 images. This is a good way to confirm your model is working as expected. Click Play on the blocks below to see how your model performs."
      ],
      "metadata": {
        "id": "BX3PTrEPacGY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PooP5Vjsg2Jn"
      },
      "outputs": [],
      "source": [
        "!yolo detect predict model=runs/detect/train/weights/best.pt source=data/validation/images save=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEEObQqoiGrs"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from IPython.display import Image, display\n",
        "for image_path in glob.glob(f'/content/runs/detect/predict/*.jpg')[:10]:\n",
        "  display(Image(filename=image_path, height=400))\n",
        "  print('\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model should draw a box around each object of interest in each image. If it isn't doing a good job of detecting objects, here are a few tips:\n",
        "\n",
        "1. Double-check your dataset to make sure there are no labeling errors or conflicting examples.\n",
        "2. Increase the number of epochs used for training.\n",
        "3. Use a larger model size (e.g. `yolo11l.pt`).\n",
        "4. Add more images to the training dataset. See my [dataset video](https://www.youtube.com/watch?v=v0ssiOY6cfg) for tips on how to capture good training images and improve accuracy.\n",
        "\n",
        "You can also run the model on video files or other images images by uploading them to this notebook and using the above `!yolo detect predict` command, where `source` points to the location of the video file, image, or folder of images. The results will be saved in `runs/detect/predict`.\n",
        "\n",
        "Drawing boxes on images is great, but it isn't very useful in itself. It's also not very helpful to just run this models inside a Colab notebook: it's easier if we can just run it on a local computer. Continue to the next section to see how to download your newly trained model and run it on a local device."
      ],
      "metadata": {
        "id": "EGiQw_gWbSBa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7yrFRViVczX"
      },
      "source": [
        "#7.&nbsp;Deploy Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that your custom model has been trained, it's ready to be downloaded and deployed in an application! YOLO models can run on a wide variety of hardware, including PCs, embedded systems, and phones. Ultralytics makes it easy to convert the YOLO models to various formats (`tflite`, `onnx`, etc.) and deploy them in a variety of environments.\n",
        "\n",
        "This section shows how to download the model and provides links to instructions for deploying it on your PC and edge devices like the Raspberry Pi."
      ],
      "metadata": {
        "id": "FEtybPmB_ERi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.1 Download YOLO Model\n",
        "\n",
        "First, zip and download the trained model by running the code blocks below.\n",
        "\n",
        "The code creates a folder named `my_model`, moves the model weights into it, and renames them from `best.pt` to `my_model.pt`. It also adds the training results in case you want to reference them later. It then zips the folder as `my_model.zip`."
      ],
      "metadata": {
        "id": "IcoBAeHXa86W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create \"my_model\" folder to store model weights and train results\n",
        "!mkdir /content/my_model\n",
        "!cp /content/runs/detect/train/weights/best.pt /content/my_model/my_model.pt\n",
        "!cp -r /content/runs/detect/train /content/my_model\n",
        "\n",
        "# Zip into \"my_model.zip\"\n",
        "%cd my_model\n",
        "!zip /content/my_model.zip my_model.pt\n",
        "!zip -r /content/my_model.zip train\n",
        "%cd /content"
      ],
      "metadata": {
        "id": "qcBdnOA9v85S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43ypwonynLVu"
      },
      "outputs": [],
      "source": [
        "# This takes forever for some reason, you can also just download the model from the sidebar\n",
        "from google.colab import files\n",
        "\n",
        "files.download('/content/my_model.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.2 Deploy YOLO Model on Local Devices\n",
        "\n",
        "Next, we'll take our downloaded model and run it on a local device. This section provides instructions showing how to deploy YOLO models on various devices.\n",
        "\n",
        "I wrote a basic Python script, `yolo_detect.py`, that shows how to load a model, run inference on an image source, parse the inference results, and display boxes around each detected class in the image. The [script](https://github.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/blob/main/yolo_detect.py) gives an example of how to work with Ultralytics YOLO models in Python, and it can be used as a starting point for more advanced applications."
      ],
      "metadata": {
        "id": "YL06c6pb_UqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2.1 Deploy on PC (Windows, Linux, or macOS)\n",
        "\n",
        "The easiest way to run Ultralytics models on a PC is using Anaconda. Anaconda sets up a virtual Python environment and allows you to easily install Ultralytics and PyTorch. It automatically installs CUDA and cuDNN, which allows you to speed up model inference with your NVIDIA GPU.\n",
        "\n",
        "> **NOTE:** My YouTube video (link to be added) shows how to deploy your model on a PC. It walks through the following steps, so watch the video if you prefer having visual instructions.\n",
        "\n",
        "**1. Download and Install Anaconda**\n",
        "\n",
        "Go to the Anaconda download page at https://anaconda.com/download, click the “skip registration” button, and then download the package for your OS. When it's finished downloading, run the installer and click through the installation steps. You can use the default options for installation.\n",
        "\n",
        "**2. Set up virtual environment**\n",
        "\n",
        "Once it's installed, run Anaconda Prompt from the Start Bar. (If you're on macOS or Linux, just open a command terminal).\n",
        "\n",
        "Issue the following commands to create a new Python environment and activate it:\n",
        "\n",
        "```\n",
        "conda create --name yolo-env1 python=3.12 -y\n",
        "conda activate yolo-env1\n",
        "```\n",
        "\n",
        "Install Ultralytics (which also installs import libraries like OpenCV-Python, Numpy, and PyTorch) by issuing the following command:\n",
        "\n",
        "```\n",
        "pip install ultralytics\n",
        "```\n",
        "\n",
        "If you have an NVIDIA GPU, you can install the GPU-enabled version of PyTorch by issuing the following command:\n",
        "\n",
        "```\n",
        "pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
        "```\n",
        "\n",
        "**3. Extract downloaded model**\n",
        "Take the `my_model.zip` file you downloaded in Step 7.1 and unzip it to a folder on your PC. In the Anaconda Prompt terminal, move into the unzipped folder using:\n",
        "\n",
        "```\n",
        "cd path/to/folder\n",
        "```\n",
        "\n",
        "**4. Download and run yolo_detect.py**\n",
        "\n",
        "Download the `yolo_detect.py` script into the `my_model` folder using:\n",
        "\n",
        "```\n",
        "curl -o yolo_detect.py https://raw.githubusercontent.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/refs/heads/main/yolo_detect.py\n",
        "```\n",
        "\n",
        "Alright! We're ready to run the script. To run inference with a yolov8s model on a USB camera at 1280x720 resolution, issue:\n",
        "\n",
        "```\n",
        "python yolo_detect.py --model my_model.pt --source usb0 --resolution 1280x720\n",
        "```\n",
        "\n",
        "A window will appear showing a live feed from your webcam with boxes drawn around detected objects in each frame.\n",
        "\n",
        "You can also run the model on an video file, image, or folder of images. To see a full list of arguments for `yolo_detect.py`, issue `python yolo_detect.py --help` or see the [README file](https://github.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/blob/main/README.md).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gzaJQ2sGEPhP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2.2 Deploy on Raspberry Pi\n",
        "\n",
        "Keep an eye out for an article showing how to convert YOLO models to NCNN format and run them on the Raspberry Pi!"
      ],
      "metadata": {
        "id": "GelkpRLPEYmJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.&nbsp;Conclusion"
      ],
      "metadata": {
        "id": "y8fOJ4g8Q5x0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congratulations! You've successfully trained and deployed a YOLO object detection model. 😀\n",
        "\n",
        "Next, you can extend your application beyond just drawing boxes and counting objects. Add functionality like logging the number of objects detected over time or taking a picture when certain objects are detected. Check out some example applications at our GitHub repository: https://github.com/EdjeElectronics/Train-and-Deploy-YOLO-Models\n",
        "\n",
        "Thanks for working through this notebook, and good luck with your projects!"
      ],
      "metadata": {
        "id": "DEZGuG1-Peg5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Appendix: Common Errors"
      ],
      "metadata": {
        "id": "fXeDs6SaQBRy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you run into any errors working through this notebook, please do the following:\n",
        "\n",
        "\n",
        "- Double-check that the dataset files are set up in the correct folder structure\n",
        "- Make sure there are no typos or errors in your labelmap file\n",
        "- Google search the error to look for solutions\n",
        "\n",
        "If none of those help, please submit an [Issue](https://github.com/EdjeElectronics/Train-and-Deploy-YOLO-Models/issues) on the GitHub page. In this section, I will add resolutions to common errors as they come up."
      ],
      "metadata": {
        "id": "Q19ENCHRQOCH"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}